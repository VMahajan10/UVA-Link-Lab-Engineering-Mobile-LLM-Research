package com.research.llmbattery.models

/**
 * Data class representing the outcome and performance metrics of a single LLM query.
 * Contains information about the query, response, timing, battery level, and model details.
 */
data class QueryResult(
    val timestamp: Long,
    val queryText: String,
    val responseText: String,
    val inferenceTimeMs: Long,
    val batteryLevel: Int,
    val quantization: String,
    val modelName: String
) {
    companion object {
        /**
         * Factory method for creating a QueryResult instance.
         * @param timestamp Timestamp of the query execution
         * @param queryText The text of the query
         * @param responseText The response generated by the LLM
         * @param inferenceTimeMs Time taken for LLM inference in milliseconds
         * @param batteryLevel Battery level at the time of query execution (0-100)
         * @param quantization The quantization type used for the model
         * @param modelName The name of the model used
         * @return A new QueryResult instance
         */
        fun create(
            timestamp: Long,
            queryText: String,
            responseText: String,
            inferenceTimeMs: Long,
            batteryLevel: Int,
            quantization: String,
            modelName: String
        ): QueryResult {
            return QueryResult(
                timestamp = timestamp,
                queryText = queryText,
                responseText = responseText,
                inferenceTimeMs = inferenceTimeMs,
                batteryLevel = batteryLevel,
                quantization = quantization,
                modelName = modelName
            )
        }
        
        /**
         * Creates a sample QueryResult for testing with default values.
         * @return A sample QueryResult instance
         */
        fun createSample(): QueryResult {
            return QueryResult(
                timestamp = System.currentTimeMillis(),
                queryText = "What is the capital of France?",
                responseText = "The capital of France is Paris.",
                inferenceTimeMs = 1250L,
                batteryLevel = 78,
                quantization = "4-bit",
                modelName = "sample-model"
            )
        }
        
        /**
         * Creates a QueryResult instance with current system time.
         * @param queryText The text of the query
         * @param responseText The response generated by the LLM
         * @param inferenceTimeMs Time taken for LLM inference in milliseconds
         * @param batteryLevel Battery level at the time of query execution (0-100)
         * @param quantization The quantization type used for the model
         * @param modelName The name of the model used
         * @return A new QueryResult instance with current timestamp
         */
        fun createNow(
            queryText: String,
            responseText: String,
            inferenceTimeMs: Long,
            batteryLevel: Int,
            quantization: String,
            modelName: String
        ): QueryResult {
            return QueryResult(
                timestamp = System.currentTimeMillis(),
                queryText = queryText,
                responseText = responseText,
                inferenceTimeMs = inferenceTimeMs,
                batteryLevel = batteryLevel,
                quantization = quantization,
                modelName = modelName
            )
        }
    }
}
